{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Video\n",
    "\n",
    "Cloud point data collect of autopilot car have LiDAR sensor and generic traffic surround.\n",
    "\n",
    "Get the cloud point data -> process and store all the frames -> create video from the frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n",
      "OpenCV: AVF: waiting to write video data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved as /Users/apple/Documents/UniversityDocument/Thesis/automative_self_driving_car/23-10-2024/videos/output2.mov\n",
      "Success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 22:59:27.787 python[86497:2171417] WARNING: -finishWriting should not be called on the main thread.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.spatial import KDTree\n",
    "import cv2\n",
    "\n",
    "from constants import *\n",
    "\n",
    "class PointCloudProcessor:\n",
    "    \"\"\"\n",
    "    Processes point cloud data frames, performs clustering, tracking, and vehicle classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, cloud_point_data, eps=EPS, min_samples=MIN_SAMPLES):\n",
    "        self.cloud_point_data = cloud_point_data\n",
    "        self.num_frames = len(cloud_point_data)\n",
    "        self.eps = eps\n",
    "        self.min_samples = min_samples\n",
    "\n",
    "        # Initialize tracking history and IDs\n",
    "        self.cluster_history = []\n",
    "        self.tracking_id = 0\n",
    "        self.cluster_color_map = {}\n",
    "        self.previous_centroids_map = {}\n",
    "        self.previous_directions_map = {}\n",
    "        self.vehicle_type_cluster = {}\n",
    "\n",
    "    def process_frames(self):\n",
    "        \"\"\"Processes each frame to perform clustering, tracking, and vehicle classification.\"\"\"\n",
    "        previous_centroids = []\n",
    "        previous_cluster_ids = []\n",
    "        for frame_idx in range(self.num_frames):\n",
    "            current_frame = self.cloud_point_data[frame_idx]\n",
    "            # Perform clustering\n",
    "            clustering = DBSCAN(eps=self.eps, min_samples=self.min_samples).fit(current_frame)\n",
    "            labels = clustering.labels_\n",
    "\n",
    "            current_centroids = []\n",
    "            cluster_points = []\n",
    "\n",
    "            # Extract clusters and centroids\n",
    "            for cluster_label in set(labels):\n",
    "                if cluster_label == -1:\n",
    "                    continue  # Skip noise points\n",
    "                \n",
    "                cluster_data = current_frame[labels == cluster_label]\n",
    "  \n",
    "                if np.any(cluster_data[:, 2] >= 2):\n",
    "                    continue\n",
    "                \n",
    "                clus_points = current_frame[labels == cluster_label]\n",
    "                cluster_points.append(clus_points)\n",
    "\n",
    "                cluster_pcd = o3d.geometry.PointCloud()\n",
    "                cluster_pcd.points = o3d.utility.Vector3dVector(clus_points)\n",
    "\n",
    "                bbox = cluster_pcd.get_axis_aligned_bounding_box()\n",
    "                bbox_center = bbox.get_center()\n",
    "                current_centroids.append(bbox_center)\n",
    "\n",
    "            current_centroids = np.array(current_centroids)\n",
    "\n",
    "            # Track clusters\n",
    "            if frame_idx == 0:\n",
    "                # For the first frame, initialize the cluster IDs\n",
    "                cluster_ids = np.arange(len(current_centroids))\n",
    "                self.tracking_id = len(current_centroids)\n",
    "            else:\n",
    "                cluster_ids, self.tracking_id = self.track_clusters(current_centroids, previous_centroids, previous_cluster_ids)\n",
    "\n",
    "            # Save the cluster history for visualization\n",
    "            self.cluster_history.append((cluster_points, current_centroids, cluster_ids))\n",
    "\n",
    "            # Update previous centroids and cluster IDs\n",
    "            previous_centroids = current_centroids\n",
    "            previous_cluster_ids = cluster_ids\n",
    "\n",
    "            # Assign colors to clusters\n",
    "            for cluster_id in cluster_ids:\n",
    "                self.assign_color(cluster_id)\n",
    "        \n",
    "    def track_clusters(self, current_centroids, previous_centroids, prev_cluster_ids, threshold=DIST_THRESHOLD_TRACKING):\n",
    "        \"\"\"Matches current centroids with previous centroids using nearest neighbor approach.\"\"\"\n",
    "        if len(previous_centroids) == 0:\n",
    "            return np.arange(len(current_centroids)) + self.tracking_id, self.tracking_id + len(current_centroids)\n",
    "        \n",
    "        # Create a KDTree for fast nearest neighbor lookup\n",
    "        tree = KDTree(previous_centroids)\n",
    "        \n",
    "        # Assign new tracking IDs based on nearest neighbors from the previous frame\n",
    "        assigned_ids = np.full(len(current_centroids), -1)  # -1 for new clusters\n",
    "        distances, indices = tree.query(current_centroids)\n",
    "        \n",
    "        # Assign tracking IDs based on distance threshold\n",
    "        for i, (dist, idx) in enumerate(zip(distances, indices)):\n",
    "            if dist < threshold:\n",
    "                assigned_ids[i] = prev_cluster_ids[idx]  # Match with existing cluster ID\n",
    "        \n",
    "        # Assign new IDs to unmatched clusters\n",
    "        new_clusters = (assigned_ids == -1)\n",
    "        assigned_ids[new_clusters] = np.arange(self.tracking_id, self.tracking_id + np.sum(new_clusters))\n",
    "        \n",
    "        return assigned_ids, self.tracking_id + np.sum(new_clusters)\n",
    "    \n",
    "    def classify_vehicle(self, bbox):\n",
    "        \"\"\"Classifies the object as a car, truck, or motorcycle based on the bounding box dimensions.\"\"\"\n",
    "        dimensions = bbox.get_extent()\n",
    "        dimensions = sorted(dimensions, reverse=True)\n",
    "        d0, d1, d2 = dimensions[0], dimensions[1], dimensions[2]\n",
    "    \n",
    "        for vehicle_type, size_range in VEHICLE_SIZE_RANGES.items():\n",
    "            if (size_range['0'][0] <= d0 <= size_range['0'][1] and\n",
    "                size_range['1'][0] <= d1 <= size_range['1'][1] and\n",
    "                size_range['2'][0] <= d2 <= size_range['2'][1]):\n",
    "                return vehicle_type\n",
    "        return None\n",
    "\n",
    "    def assign_color(self, cluster_id):\n",
    "        \"\"\"Assigns a color to a cluster if not already assigned.\"\"\"\n",
    "        if cluster_id not in self.cluster_color_map:\n",
    "            color_index = len(self.cluster_color_map) % len(COLOR_NAMES)  # Cycle through the color list\n",
    "            self.cluster_color_map[cluster_id] = (COLOR_NAMES[color_index], COLOR_VALUES[COLOR_NAMES[color_index]])\n",
    "        \n",
    "    def create_arrow(self, start, end, bbox, previous_direction=None, scale_factor=ARROW_SCALE_FACTOR):\n",
    "        \"\"\"\n",
    "        Creates an arrow mesh representing movement direction with a scaled length based on the magnitude of the vector.\n",
    "        Uses Exponential Moving Average (EMA) for smoothing the direction.\n",
    "        \"\"\"\n",
    "        kmh = self.find_velocity_kmh(end, start)\n",
    "        \n",
    "        if kmh > VELOCITY_THRESHOLD:\n",
    "            # Calculate the direction vector\n",
    "            new_direction = end - start\n",
    "            new_direction[2] = 0  # Ignore Z-axis movement for 2D plane movement visualization\n",
    "    \n",
    "            # If there is a previous direction, update it using exponential moving average\n",
    "            if previous_direction is not None:\n",
    "                updated_direction = 0.7 * previous_direction + 0.3 * new_direction  # Apply EMA\n",
    "            else:\n",
    "                updated_direction = new_direction\n",
    "    \n",
    "            # Calculate the magnitude (length) of the direction vector\n",
    "            length = np.linalg.norm(updated_direction)\n",
    "    \n",
    "            if length == 0:\n",
    "                return None  # No arrow needed if there's no movement\n",
    "    \n",
    "            # Scale the arrow length by a given factor\n",
    "            scaled_length = length * scale_factor\n",
    "    \n",
    "            # Normalize the updated direction vector\n",
    "            updated_direction_normalized = updated_direction / length\n",
    "    \n",
    "            # Create an arrow mesh with length proportional to the scaled movement\n",
    "            arrow1 = o3d.geometry.TriangleMesh.create_arrow(cylinder_radius=0.1, cone_radius=0.2,\n",
    "                                                           cylinder_height=scaled_length * 0.3, cone_height=scaled_length * 0.2)\n",
    "            arrow2 = o3d.geometry.TriangleMesh.create_arrow(cylinder_radius=0.1, cone_radius=0.2,\n",
    "                                                           cylinder_height=scaled_length * 0.3, cone_height=scaled_length * 0.2)\n",
    "    \n",
    "            # Align the arrow with the updated direction vector\n",
    "            z_unit_vector = np.array([0, 0, 1])  # Upward vector\n",
    "            axis = np.cross(z_unit_vector, updated_direction_normalized)\n",
    "            axis_length = np.linalg.norm(axis)\n",
    "    \n",
    "            if axis_length != 0:\n",
    "                axis /= axis_length  # Normalize the axis of rotation\n",
    "                angle = np.arccos(np.clip(np.dot(z_unit_vector, updated_direction_normalized), -1.0, 1.0))\n",
    "                R = o3d.geometry.get_rotation_matrix_from_axis_angle(axis * angle)\n",
    "                arrow1.rotate(R, center=(0, 0, 0))\n",
    "                arrow2.rotate(R, center=(0, 0, 0))\n",
    "\n",
    "            front_top_center, back_top_center = self.find_top_edge_centers(bbox)\n",
    "            # Translate the arrow to start from the previous centroid (start position)\n",
    "            arrow1.translate(front_top_center)\n",
    "            arrow2.translate(back_top_center)\n",
    "            arrow1.paint_uniform_color([1, 0, 1])  # Set arrow color to purple\n",
    "            arrow2.paint_uniform_color([1, 0, 1])  # Set arrow color to purple\n",
    "    \n",
    "            return arrow1, arrow2\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def find_velocity_kmh(self, start, end, time=1/20):\n",
    "        \"\"\"Computes velocity in km/h between two points.\"\"\"\n",
    "        v = np.linalg.norm(end - start) / time\n",
    "        kmh = int(3.6 * v)\n",
    "        return kmh\n",
    "    \n",
    "    def find_top_edge_centers(self, bbox):\n",
    "        bbox_corners = np.asarray(bbox.get_box_points())\n",
    "        top_face_points = bbox_corners[bbox_corners[:, 2] == np.max(bbox_corners[:, 2])]\n",
    "        edges = {\n",
    "            ('0', '1'): np.linalg.norm(top_face_points[0] - top_face_points[1]),\n",
    "            ('0', '2'): np.linalg.norm(top_face_points[0] - top_face_points[2]),\n",
    "            ('0', '3'): np.linalg.norm(top_face_points[0] - top_face_points[3]),\n",
    "            ('1', '2'): np.linalg.norm(top_face_points[1] - top_face_points[2]),\n",
    "            ('1', '3'): np.linalg.norm(top_face_points[1] - top_face_points[3]),\n",
    "            ('2', '3'): np.linalg.norm(top_face_points[2] - top_face_points[3])\n",
    "        }\n",
    "\n",
    "        sorted_edges = sorted(edges.items(), key=lambda x: x[1], reverse=True)\n",
    "        a, b = sorted_edges[4][0]\n",
    "        c, d = sorted_edges[5][0]\n",
    "        front = (top_face_points[int(a)]+top_face_points[int(b)])/2\n",
    "        front[2] = top_face_points[int(a)][2]\n",
    "        back = (top_face_points[int(c)]+top_face_points[int(d)])/2\n",
    "        back[2] = top_face_points[int(c)][2]\n",
    "        return front, back\n",
    "\n",
    "\n",
    "class Visualizer:\n",
    "    \"\"\"\n",
    "    Handles visualization of point cloud data, bounding boxes, centroids, and movement arrows.\n",
    "    Saves frames as images.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_dir, output_video='output.mov', frame_rate=FRAME_RATE):\n",
    "        self.output_dir = output_dir\n",
    "        self.output_video = output_video\n",
    "        self.frame_rate = frame_rate\n",
    "\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "        self.vis = self.setup_visualizer()\n",
    "\n",
    "    def setup_visualizer(self):\n",
    "        \"\"\"Sets up Open3D visualizer with camera parameters.\"\"\"\n",
    "        vis = o3d.visualization.Visualizer()\n",
    "        vis.create_window(visible=False)\n",
    "        return vis\n",
    "\n",
    "    def visualize(self, processor):\n",
    "        \"\"\"Visualizes each frame using the processed data from PointCloudProcessor.\"\"\"\n",
    "        for frame_idx, (cluster_points, centroids, cluster_ids) in enumerate(processor.cluster_history):\n",
    "            all_points = []\n",
    "            all_colors = []\n",
    "            bounding_boxes = []\n",
    "            centroids_spheres = []\n",
    "            arrows = []  # To store arrows between previous and current centroids\n",
    "            previous_centroids_spheres = []  # To store previous centroids as spheres\n",
    "\n",
    "            for i, cluster in enumerate(cluster_points):\n",
    "                # Add all points to the list for visualization\n",
    "                all_points.append(cluster)\n",
    "                \n",
    "                # Create an Open3D point cloud for the current cluster\n",
    "                cluster_pcd = o3d.geometry.PointCloud()\n",
    "                cluster_pcd.points = o3d.utility.Vector3dVector(cluster)\n",
    "                \n",
    "                # Compute the bounding box for the cluster\n",
    "                bbox = cluster_pcd.get_axis_aligned_bounding_box()\n",
    "                bbox_center = bbox.get_center()\n",
    "\n",
    "                # Ensure that the color is assigned\n",
    "                processor.assign_color(cluster_ids[i])\n",
    "                \n",
    "                vehicle_type = processor.classify_vehicle(bbox)\n",
    "                \n",
    "                if (cluster_ids[i] in processor.vehicle_type_cluster) and ((vehicle_type == None) or vehicle_type == processor.vehicle_type_cluster[cluster_ids[i]]):\n",
    "                    vehicle_type = processor.vehicle_type_cluster[cluster_ids[i]]\n",
    "                elif (cluster_ids[i] in processor.vehicle_type_cluster) and (vehicle_type != None) and vehicle_type != processor.vehicle_type_cluster[cluster_ids[i]]:\n",
    "                    processor.vehicle_type_cluster[cluster_ids[i]] = vehicle_type\n",
    "\n",
    "                if vehicle_type:\n",
    "                    # Add the bounding box to the list for visualization\n",
    "                    bbox.color = (0, 1, 0)  # Set bounding box color (e.g., green)\n",
    "                    bounding_boxes.append(bbox)\n",
    "\n",
    "                    centroid_color = VEHICLE_CENTROID_COLORS[vehicle_type]  # Color based on vehicle type\n",
    "\n",
    "                    # Set the color of the entire point cloud cluster to match the centroid color\n",
    "                    all_colors.append(np.tile(centroid_color, (len(cluster), 1)))  # Apply centroid color to the points\n",
    "\n",
    "                    # Check if we have a previous centroid for this cluster to draw an arrow\n",
    "                    if cluster_ids[i] in processor.previous_centroids_map:\n",
    "                        prev_centroid = processor.previous_centroids_map[cluster_ids[i]]\n",
    "                        \n",
    "                        # Get the previous direction if it exists\n",
    "                        previous_direction = processor.previous_directions_map.get(cluster_ids[i], None)\n",
    "\n",
    "                        # Create and append the arrow with EMA\n",
    "                        arrow_result = processor.create_arrow(prev_centroid, bbox_center, bbox, previous_direction)\n",
    "                        if arrow_result is not None:\n",
    "                            arrow1, arrow2 = arrow_result\n",
    "                            arrows.append(arrow1)\n",
    "                            arrows.append(arrow2)\n",
    "\n",
    "                        \n",
    "                        # Store the new direction for future EMA updates\n",
    "                        new_direction = bbox_center - prev_centroid\n",
    "                        processor.previous_directions_map[cluster_ids[i]] = new_direction  # Update the direction map\n",
    "\n",
    "                        # Create a sphere at the previous centroid (grey color)\n",
    "                        prev_sphere = o3d.geometry.TriangleMesh.create_sphere(radius=0.05)\n",
    "                        prev_sphere.translate(prev_centroid)\n",
    "                        prev_sphere.paint_uniform_color([0.5, 0.5, 0.5])  # Grey color for previous centroids\n",
    "                        previous_centroids_spheres.append(prev_sphere)\n",
    "                    \n",
    "                    # Update the previous centroid for this cluster\n",
    "                    processor.previous_centroids_map[cluster_ids[i]] = bbox_center\n",
    "                    \n",
    "                else:\n",
    "                    centroid_color = [0, 0, 1]  # Default blue if no vehicle classification\n",
    "                    all_colors.append(np.tile(centroid_color, (len(cluster), 1)))  # Apply default color to points\n",
    "                \n",
    "                # Create a sphere at the centroid with the appropriate vehicle type color\n",
    "                sphere = o3d.geometry.TriangleMesh.create_sphere(radius=0.1)\n",
    "                sphere.translate(bbox_center)\n",
    "                sphere.paint_uniform_color(centroid_color)  # Set centroid color based on vehicle type\n",
    "                centroids_spheres.append(sphere)\n",
    "\n",
    "            if len(all_points) > 0:\n",
    "                # Flatten the points and colors arrays for visualization\n",
    "                all_points = np.vstack(all_points)\n",
    "                all_colors = np.vstack(all_colors)\n",
    "                \n",
    "                # Create an Open3D point cloud object for visualization\n",
    "                pcd = o3d.geometry.PointCloud()\n",
    "                pcd.points = o3d.utility.Vector3dVector(all_points)\n",
    "                pcd.colors = o3d.utility.Vector3dVector(all_colors)\n",
    "            \n",
    "                # Visualize all points with bounding boxes, tracked cluster colors, current and previous centroids, and arrows\n",
    "                self.visualize_frame(pcd, bounding_boxes, arrows, frame_idx)\n",
    "\n",
    "    def visualize_frame(self, cloud, bounding_boxes, arrows, frame_idx):\n",
    "        \"\"\"Renders the current frame with the visualizer and saves it as an image.\"\"\"\n",
    "        self.vis.clear_geometries()\n",
    "        entities_to_draw = [cloud] + bounding_boxes + arrows\n",
    "\n",
    "        for entity in entities_to_draw:\n",
    "            self.vis.add_geometry(entity)\n",
    "\n",
    "        self.vis.poll_events()\n",
    "        self.vis.update_renderer()\n",
    "\n",
    "        frame_image = np.array(self.vis.capture_screen_float_buffer(True)) * 255\n",
    "        frame_image = frame_image.astype(np.uint8)\n",
    "\n",
    "        frame_filename = os.path.join(self.output_dir, f\"frame_{frame_idx:04d}.png\")\n",
    "        cv2.imwrite(frame_filename, frame_image)\n",
    "        \n",
    "    def close(self):\n",
    "        self.vis.destroy_window()\n",
    "        \n",
    "\n",
    "class VideoCreator:\n",
    "    \"\"\"\n",
    "    Creates a video from the saved frame images.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_dir, output_video='output.mov', frame_rate=FRAME_RATE):\n",
    "        self.output_dir = output_dir\n",
    "        self.output_video = output_video\n",
    "        self.frame_rate = frame_rate\n",
    "        \n",
    "    def get_frame_count(self):\n",
    "        \"\"\"Counts the number of frame images in the output directory.\"\"\"\n",
    "        files = [f for f in os.listdir(self.output_dir) if os.path.isfile(os.path.join(self.output_dir, f)) and f.startswith('frame_') and f.endswith('.png')]\n",
    "        return len(files)\n",
    "\n",
    "\n",
    "    def create_video_from_frames(self):\n",
    "        \"\"\"Combines saved frame images into a video.\"\"\"\n",
    "        frame_filename = os.path.join(self.output_dir, \"frame_0000.png\")\n",
    "        frame = cv2.imread(frame_filename)\n",
    "\n",
    "        if frame is None:\n",
    "            print(\"Error: Could not load the first frame.\")\n",
    "            return\n",
    "        \n",
    "        num_frames = self.get_frame_count()\n",
    "        \n",
    "        height, width, _ = frame.shape\n",
    "        fourcc = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')\n",
    "        video_writer = cv2.VideoWriter(\n",
    "            self.output_video, fourcc, self.frame_rate, (width, height))\n",
    "\n",
    "        for frame_idx in range(num_frames):\n",
    "            frame_filename = os.path.join(self.output_dir, f\"frame_{frame_idx:04d}.png\")\n",
    "            frame = cv2.imread(frame_filename)\n",
    "            if frame is not None:\n",
    "                video_writer.write(frame)\n",
    "            else:\n",
    "                print(f\"Frame {frame_idx} not found or couldn't be loaded.\")\n",
    "\n",
    "        video_writer.release()\n",
    "        print(f\"Video saved as {self.output_video}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        cloud_point_data = np.load('/Users/apple/Documents/UniversityDocument/Thesis/automative_self_driving_car/23-10-2024/data/cloud_point_data.pkl', allow_pickle=True)\n",
    "\n",
    "        output_dir = '/Users/apple/Documents/UniversityDocument/Thesis/automative_self_driving_car/23-10-2024/frames'\n",
    "        output_video = '/Users/apple/Documents/UniversityDocument/Thesis/automative_self_driving_car/23-10-2024/videos/output2.mov'\n",
    "        processor = PointCloudProcessor(cloud_point_data)\n",
    "        processor.process_frames()\n",
    "        visualizer = Visualizer(output_dir, output_video=output_video)\n",
    "        visualizer.visualize(processor)\n",
    "        \n",
    "        video_creator = VideoCreator(output_dir, output_video=output_video)\n",
    "        video_creator.create_video_from_frames()\n",
    "        visualizer.close()\n",
    "    finally:\n",
    "        print(\"Success\")\n",
    "        \n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
