{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNUByJlQ608Xxr9/yJL81Gj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"unHTL8Fsje3h","executionInfo":{"status":"ok","timestamp":1731686492000,"user_tz":-420,"elapsed":32575,"user":{"displayName":"Hung To","userId":"12784896086462809074"}},"outputId":"b4d7722d-d8a6-4456-e909-1e9f169f76b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import carla #the sim library itself\n","import time # to set a delay after each photo\n","import cv2 #to work with images from cameras\n","import numpy as np #in this example to change image representation - re-shaping\n","import math\n","import sys\n","import random\n","sys.path.append('C:/CARLA_0.9.13/PythonAPI/carla') # tweak to where you put carla\n","from tensorflow.keras.models import load_model\n","from agents.navigation.global_route_planner import GlobalRoutePlanner\n","from matplotlib import pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import transforms\n","\n","\n","PREFERRED_SPEED = 30\n","SPEED_THRESHOLD = 2\n","\n","MAX_STEER_DEGREES = 40\n","STEERING_CONVERSION = 75\n","\n","CAMERA_POS_Z = 1.3\n","CAMERA_POS_X = 1.4\n","\n","HEIGHT = 180\n","WIDTH = 320\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# utility function for camera listening\n","def camera_callback(image,data_dict):\n","    data_dict['image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))[:, :, :3]\n","\n","\n","def sem_callback(image,data_dict):\n","    ########## IMPORTANT CHANGE for Semantic camera ##############\n","    image.convert(carla.ColorConverter.CityScapesPalette)\n","    data_dict['sem_image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))[:, :, :3]\n","\n","# maintain speed function\n","def maintain_speed(s):\n","    '''\n","    this is a very simple function to maintan desired speed\n","    s arg is actual current speed\n","    '''\n","    if s >= PREFERRED_SPEED:\n","        return 0\n","    elif s < PREFERRED_SPEED - SPEED_THRESHOLD:\n","        return 0.9 # think of it as % of \"full gas\"\n","    else:\n","        return 0.4 # tweak this if the car is way over or under preferred speed\n","\n","\n","# function to get angle between the car and target waypoint\n","def get_angle(car,wp):\n","    vehicle_pos = car.get_transform()\n","    car_x = vehicle_pos.location.x\n","    car_y = vehicle_pos.location.y\n","    wp_x = wp.transform.location.x\n","    wp_y = wp.transform.location.y\n","\n","    # vector to waypoint\n","    x = (wp_x - car_x)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n","    y = (wp_y - car_y)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n","\n","    #car vector\n","    car_vector = vehicle_pos.get_forward_vector()\n","    degrees = math.degrees(np.arctan2(y, x) - np.arctan2(car_vector.y, car_vector.x))\n","    # extra checks on predicted angle when values close to 360 degrees are returned\n","    if degrees<-180:\n","        degrees = degrees + 360\n","    elif degrees > 180:\n","        degrees = degrees - 360\n","    return degrees\n","\n","def get_proper_angle(car,wp_idx,rte):\n","    # create a list of angles to next 5 waypoints starting with current\n","    next_angle_list = []\n","    for i in range(10):\n","        if wp_idx + i*3 <len(rte)-1:\n","            next_angle_list.append(get_angle(car,rte[wp_idx + i*3][0]))\n","    idx = 0\n","    while idx<len(next_angle_list)-2 and abs(next_angle_list[idx])>40:\n","        idx +=1\n","    return wp_idx+idx*3,next_angle_list[idx]\n","\n","def get_distant_angle(car,wp_idx,rte, delta):\n","    if wp_idx + delta < len(rte)-1:\n","        i = wp_idx + delta\n","    else:\n","        i = len(rte)-1\n","    intersection_detected = False\n","    for x in range(i-wp_idx):\n","        if rte[wp_idx+x][0].is_junction:\n","             intersection_detected = True\n","    angle = get_angle(car,rte[i][0])\n","    if not intersection_detected:\n","        result = 0\n","    elif angle <-10:\n","        result = -1\n","    elif angle>10:\n","        result =1\n","    else:\n","        result = 0\n","    return result\n","\n","def draw_route(wp, route,seconds=3.0):\n","        draw_colour = carla.Color(r=255, g=0, b=0)\n","    else:\n","        draw_colour = carla.Color(r=0, g=0, b=255)\n","    for i in range(10):\n","        if wp+i<len(route)-2:\n","            world.debug.draw_string(route[wp+i][0].transform.location, '^', draw_shadow=False,\n","                color=draw_colour, life_time=seconds,\n","                persistent_lines=True)\n","    return None\n","\n","def select_random_route(position,locs):\n","    point_a = position.location #we start at where the car is or last waypoint\n","    sampling_resolution = 1\n","    grp = GlobalRoutePlanner(world.get_map(), sampling_resolution)\n","    # now let' pick the longest possible route\n","    min_distance = 100\n","    result_route = None\n","    route_list = []\n","    for loc in locs: # we start trying all spawn points\n","                                #but we just exclude first at zero index\n","        cur_route = grp.trace_route(point_a, loc.location)\n","        if len(cur_route) > min_distance:\n","            route_list.append(cur_route)\n","    result_route = random.choice(route_list)\n","    return result_route\n","\n","\n","def exit_clean():\n","    for sensor in world.get_actors().filter('*sensor*'):\n","        sensor.destroy()\n","    for actor in world.get_actors().filter('*vehicle*'):\n","        actor.destroy()\n","    return None\n","\n","\n","pcd = None\n","\n","def lidar_callback(point_cloud, point_list):\n","    \"\"\"Prepares a point cloud with intensity\n","    colors ready to be consumed by Open3D\"\"\"\n","    data = np.copy(np.frombuffer(point_cloud.raw_data, dtype=np.dtype('f4')))\n","    data = np.reshape(data, (int(data.shape[0] / 4), 4))\n","    points = data[:, :-1]\n","    points[:, :1] = -points[:, :1]\n","\n","    pcd = points\n","\n","\n","def generate_lidar_bp(blueprint_library):\n","    \"\"\"Generates a CARLA blueprint based on the script parameters\"\"\"\n","    lidar_bp = blueprint_library.find('sensor.lidar.ray_cast')\n","\n","    lidar_bp.set_attribute('upper_fov', str(10.0))\n","    lidar_bp.set_attribute('lower_fov', str(-30.0))\n","    lidar_bp.set_attribute('channels', str(64.0))\n","    lidar_bp.set_attribute('range', str(100.0))\n","    lidar_bp.set_attribute('rotation_frequency', str(20))\n","    lidar_bp.set_attribute('points_per_second', str(1000000))\n","    return lidar_bp\n","\n","\n","def convert_lidar_to_pgm_polar(lidar_data, num_layers=64, num_angular_steps=360, max_range=100.0):\n","    x, y, z = lidar_data[:, 0], lidar_data[:, 1], lidar_data[:, 2]\n","    r = np.sqrt(x**2 + y**2)  # Radial distance\n","    theta = np.arctan2(y, x)  # Angle in radians\n","    theta_degrees = np.degrees(theta)  # Convert to degrees\n","    theta_degrees = (theta_degrees + 360) % 360  # Ensure range [0, 360)\n","\n","    # Discretize theta into bins\n","    angular_step_size = 360.0 / num_angular_steps\n","    theta_bins = (theta_degrees / angular_step_size).astype(int)\n","\n","    # Normalize z values into layer indices\n","    layer_indices = ((z - np.min(z)) / (np.max(z) - np.min(z)) * (num_layers - 1)).astype(int)\n","\n","    # Initialize a 2D grid (n x m) for PGM image\n","    pgm_grid = np.full((num_layers, num_angular_steps), 0, dtype=np.uint8)\n","\n","    # Populate the PGM grid\n","    for i in range(len(lidar_data)):\n","        layer = layer_indices[i]\n","        angle_bin = theta_bins[i]\n","        distance = min(r[i], max_range)  # Clip the distance to max_range\n","        normalized_distance = int((distance / max_range) * 255)  # Normalize to [0, 255]\n","        pgm_grid[layer, angle_bin] = max(pgm_grid[layer, angle_bin], normalized_distance)\n","\n","    return pgm_grid\n","\n","\n","def generate_traffic(world, client, num_vehicles=50, num_pedestrians=10):\n","\n","    vehicles_list = []\n","    walkers_list = []\n","    all_id = []\n","\n","    # Setup Traffic Manager\n","    traffic_manager = client.get_trafficmanager(8000)\n","    traffic_manager.set_global_distance_to_leading_vehicle(2.5)\n","    traffic_manager.set_synchronous_mode(True)\n","    world_settings = world.get_settings()\n","    world_settings.synchronous_mode = True\n","    world.apply_settings(world_settings)\n","\n","    # Get blueprints\n","    vehicle_blueprints = world.get_blueprint_library().filter('vehicle.*')\n","    walker_blueprints = world.get_blueprint_library().filter('walker.pedestrian.*')\n","\n","    # Spawn vehicles\n","    spawn_points = world.get_map().get_spawn_points()\n","    random.shuffle(spawn_points)\n","    batch = []\n","\n","    for n, transform in enumerate(spawn_points[:num_vehicles]):\n","        blueprint = random.choice(vehicle_blueprints)\n","        if blueprint.has_attribute('color'):\n","            color = random.choice(blueprint.get_attribute('color').recommended_values)\n","            blueprint.set_attribute('color', color)\n","        blueprint.set_attribute('role_name', 'autopilot')\n","        batch.append(carla.command.SpawnActor(blueprint, transform)\n","                        .then(carla.command.SetAutopilot(carla.command.FutureActor, True, traffic_manager.get_port())))\n","\n","    for response in client.apply_batch_sync(batch, True):\n","        if not response.error:\n","            vehicles_list.append(response.actor_id)\n","\n","    # Spawn pedestrians\n","    walker_spawn_points = []\n","    for _ in range(num_pedestrians):\n","        spawn_point = carla.Transform()\n","        loc = world.get_random_location_from_navigation()\n","        if loc:\n","            spawn_point.location = loc\n","            walker_spawn_points.append(spawn_point)\n","\n","    walker_batch = []\n","    walker_speeds = []\n","\n","    for spawn_point in walker_spawn_points:\n","        walker_bp = random.choice(walker_blueprints)\n","        walker_bp.set_attribute('is_invincible', 'false')\n","        walker_batch.append(carla.command.SpawnActor(walker_bp, spawn_point))\n","\n","    walker_results = client.apply_batch_sync(walker_batch, True)\n","    for result in walker_results:\n","        if not result.error:\n","            walkers_list.append({\"id\": result.actor_id})\n","\n","    # Add walker controllers\n","    walker_controller_bp = world.get_blueprint_library().find('controller.ai.walker')\n","    controller_batch = []\n","    for walker in walkers_list:\n","        controller_batch.append(carla.command.SpawnActor(walker_controller_bp, carla.Transform(), walker[\"id\"]))\n","\n","    controller_results = client.apply_batch_sync(controller_batch, True)\n","    for i, result in enumerate(controller_results):\n","        if not result.error:\n","            walkers_list[i][\"con\"] = result.actor_id\n","            all_id.append(walkers_list[i][\"con\"])\n","            all_id.append(walkers_list[i][\"id\"])\n","\n","    all_actors = world.get_actors(all_id)\n","\n","    # Start the walkers\n","    for i in range(0, len(all_id), 2):\n","        all_actors[i].start()\n","        all_actors[i].go_to_location(world.get_random_location_from_navigation())\n","        all_actors[i].set_max_speed(1 + random.random())  # Random speed for walkers\n","\n","    print(f\"Spawned {len(vehicles_list)} vehicles and {len(walkers_list)} pedestrians.\")\n","\n","\n","class ObstacleDetectorModel(nn.Module):\n","    def __init__(self):\n","        super(ObstacleDetectorModel, self).__init__()\n","\n","        # Convolutional layers for PGM input\n","        self.pgm_branch = nn.Sequential(\n","            nn.Conv2d(1, 32, kernel_size=3, padding=1),  # Assuming PGM is grayscale (1 channel)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Flatten()\n","        )\n","\n","        # Convolutional layers for segmentation input\n","        self.seg_branch = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # Assuming segmentation is RGB (3 channels)\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Flatten()\n","        )\n","\n","        # Fully connected layers after concatenation\n","        self.fc = nn.Sequential(\n","            nn.Linear(128 * ((HEIGHT // 8) * (WIDTH // 8)) * 2, 128),  # Adjust based on the final size of the flattened layers\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(128, 1),\n","            nn.Sigmoid()  # Output a probability for obstacle presence\n","        )\n","\n","    def forward(self, pgm_input, seg_input):\n","        pgm_features = self.pgm_branch(pgm_input)\n","        seg_features = self.seg_branch(seg_input)\n","\n","        # Concatenate the features from both branches\n","        combined_features = torch.cat((pgm_features, seg_features), dim=1)\n","\n","        # Pass through fully connected layers\n","        output = self.fc(combined_features)\n","        return output\n","\n","\n","class AutoNaviModel(nn.Module):\n","    def __init__(self):\n","        super(AutoNaviModel, self).__init__()\n","        self.conv_layers = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Flatten(),\n","            nn.Linear(64 * (HEIGHT // 8) * (WIDTH // 8), 128),\n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.Linear(128, 4),\n","            nn.ReLU(),\n","            nn.Flatten()\n","        )\n","        self.output_layer = nn.Linear(5, 1)  # 4 from image + 1 from input_2\n","\n","    def forward(self, image, navigational_direction):\n","        image_features = self.conv_layers(image)\n","        combined = torch.cat((image_features, navigational_direction.unsqueeze(1)), dim=1)\n","        output = self.output_layer(combined)\n","        return output\n","\n","\n","def control_car(sem_image, pgm_image, navigational_direction):\n","    transform = transforms.Compose([\n","        transforms.Resize((HEIGHT, WIDTH)),\n","        transforms.ToTensor(),\n","    ])\n","    sem_image = transform(sem_image).unsqueeze(0).to(DEVICE)\n","    pgm_image = transform(pgm_image).unsqueeze(0).to(DEVICE)\n","\n","    with torch.no_grad():\n","        auto_navi_output = auto_navi_model(sem_image, navigational_direction)\n","        obsta_output = obsta_model(pgm_image, sem_image)\n","\n","    return float(auto_navi_output), round(obsta_output)\n","\n","\n","auto_navi_model_path = '/content/drive/MyDrive/Thesis/Self-Driving-Car/Auto-Navi/models/auto_navi_model.pth'\n","obsta_model_path = '/content/drive/MyDrive/Thesis/Self-Driving-Car/Auto-Navi/models/obsta_model.pth'\n","\n","auto_navi_model = torch.load(auto_navi_model_path, map_location=torch.device(DEVICE))\n","obsta_model = torch.load(obsta_model_path,map_location=torch.device(DEVICE))\n","\n","auto_navi_model.eval()\n","obsta_model.eval()\n"],"metadata":{"id":"RRdBQc0ykEKh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#main loop\n","client = carla.Client('localhost', 2000)\n","world = client.get_world()\n","spawn_points = world.get_map().get_spawn_points()\n","\n","vehicle_bp = world.get_blueprint_library().filter('*model3*')[0]\n","quit = False\n","image_w = 640\n","image_h = 480\n","\n","while True:\n","    start_point = random.choice(spawn_points)\n","    vehicle = world.try_spawn_actor(vehicle_bp[0], start_point)\n","    time.sleep(2)\n","\n","    blueprint_library = world.get_blueprint_library()\n","\n","    camera_bp = blueprint_library.find('sensor.camera.semantic_segmentation')\n","    camera_bp.set_attribute('fov', '90')\n","    camera_bp.set_attribute('image_size_x', f'{image_w}')\n","    camera_bp.set_attribute('image_size_y', f'{image_h}')\n","    camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))\n","    camera_sem = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)\n","    camera_data = {'sem_image': np.zeros((image_h,image_w,4))}\n","    camera_sem.listen(lambda image: sem_callback(image,camera_data))\n","\n","\n","    lidar_bp = generate_lidar_bp(blueprint_library)\n","    lidar_transform = carla.Transform(carla.Location(x=0, z=2))\n","    lidar = world.spawn_actor(lidar_bp, lidar_transform, attach_to=vehicle)\n","    point_list = o3d.geometry.PointCloud()\n","    lidar.listen(lambda data: lidar_callback(data, point_list))\n","\n","    route = select_random_route(start_point,spawn_points)\n","    curr_wp = 5\n","    predicted_angle = 0\n","    PREFERRED_SPEED = 40\n","\n","\n","    while curr_wp<len(route)-1:\n","        world.tick()\n","        draw_route(curr_wp, route,1)\n","        if cv2.waitKey(1) == ord('q'):\n","            quit = True\n","            exit_clean()\n","            break\n","\n","        sem_image = camera_data['sem_image']\n","        sem_image = cv2.resize(sem_image, (WIDTH,HEIGHT))\n","\n","        if curr_wp >=len(route)-10:\n","            PREFERRED_SPEED = 0\n","            exit_clean()\n","            break\n","\n","        while curr_wp<len(route)-2 and vehicle.get_transform().location.distance(route[curr_wp][0].transform.location)<5:\n","            curr_wp +=1 #move to next wp if we are too close\n","        curr_wp, predicted_angle = get_proper_angle(vehicle,curr_wp,route)\n","        distant_angle = get_distant_angle(vehicle,curr_wp,route,30)\n","\n","        v = vehicle.get_velocity()\n","        speed = round(3.6 * math.sqrt(v.x**2 + v.y**2 + v.z**2),0)\n","\n","        estimated_throttle = maintain_speed(speed)\n","\n","        pgm_image = convert_lidar_to_pgm_polar(pcd)\n","\n","        steer_input, obstacle_detection = control_car(sem_image, pgm_image, distant_angle)\n","\n","        if obstacle_detection == 0:\n","            vehicle.apply_control(carla.VehicleControl(throttle=float(estimated_throttle), steer=steer_input))\n","        elif obstacle_detection == 1:\n","            vehicle.apply_control(carla.VehicleControl(throttle=0.0, brake=1.0))\n","\n","    if quit:\n","        break\n","\n"],"metadata":{"id":"0TDekOfIjmWl"},"execution_count":null,"outputs":[]}]}