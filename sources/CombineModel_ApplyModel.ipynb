{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32575,"status":"ok","timestamp":1731686492000,"user":{"displayName":"Hung To","userId":"12784896086462809074"},"user_tz":-420},"id":"unHTL8Fsje3h","outputId":"b4d7722d-d8a6-4456-e909-1e9f169f76b1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RRdBQc0ykEKh"},"outputs":[],"source":["import carla #the sim library itself\n","import time # to set a delay after each photo\n","import cv2 #to work with images from cameras\n","import numpy as np #in this example to change image representation - re-shaping\n","import math\n","import sys\n","import random\n","sys.path.append(r'C:\\Users\\Administrator\\Downloads\\WindowsNoEditor\\PythonAPI\\carla') # tweak to where you put carla\n","\n","from agents.navigation.global_route_planner import GlobalRoutePlanner\n","from matplotlib import pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import transforms\n","import open3d as o3d\n","\n","from PIL import Image\n","\n","PREFERRED_SPEED = 20\n","SPEED_THRESHOLD = 2\n","\n","MAX_STEER_DEGREES = 30\n","STEERING_CONVERSION = 75\n","\n","CAMERA_POS_Z = 1.3\n","CAMERA_POS_X = 1.4\n","\n","HEIGHT = 180\n","WIDTH = 320\n","X_MIN = -6\n","X_MAX = -1\n","Y_MIN = -1\n","Y_MAX = 1\n","Z_MIN = -1\n","Z_MAX = 2\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","def update_spectator(vehicle):\n","    vehicle_transform = vehicle.get_transform()\n","\n","    # Position the spectator slightly behind and above the vehicle\n","    spectator_location = vehicle_transform.location + carla.Location(x=0, z=40)  # Adjust x and z values as needed for view angle\n","    spectator_rotation = carla.Rotation(pitch=-90, yaw=vehicle_transform.rotation.yaw)  # Adjust pitch for angle\n","\n","    spectator_transform = carla.Transform(spectator_location, spectator_rotation)\n","    spectator.set_transform(spectator_transform)\n","\n","pcd1 = []\n","\n","def lidar_callback(point_cloud, point_list):\n","    \"\"\"Prepares a point cloud with intensity\n","    colors ready to be consumed by Open3D\"\"\"\n","    data = np.copy(np.frombuffer(point_cloud.raw_data, dtype=np.dtype('f4')))\n","    data = np.reshape(data, (int(data.shape[0] / 4), 4))\n","    points = data[:, :-1]\n","    points[:, :1] = -points[:, :1]\n","\n","    pcd1.append(points)\n","\n","def generate_lidar_bp(blueprint_library):\n","    \"\"\"Generates a CARLA blue\n","    based on the script parameters\"\"\"\n","    lidar_bp = blueprint_library.find('sensor.lidar.ray_cast')\n","\n","    lidar_bp.set_attribute('upper_fov', str(10.0))\n","    lidar_bp.set_attribute('lower_fov', str(-30.0))\n","    lidar_bp.set_attribute('channels', str(64.0))\n","    lidar_bp.set_attribute('range', str(100.0))\n","    lidar_bp.set_attribute('rotation_frequency', str(20))\n","    lidar_bp.set_attribute('points_per_second', str(1000000))\n","    return lidar_bp\n","\n","\n","def filter_points(points, x_min=X_MIN, x_max=X_MAX, y_min=Y_MIN, y_max=Y_MAX, z_min=Z_MIN, z_max=Z_MAX):\n","    mask = (\n","        (points[:, 0] >= x_min) & (points[:, 0] <= x_max) &  # x-axis (front)\n","        (points[:, 1] >= y_min) & (points[:, 1] <= y_max) &  # y-axis (lateral)\n","        (points[:, 2] >= z_min) & (points[:, 2] <= z_max)    # z-axis (height)\n","    )\n","    return np.any(mask), mask, points[mask]  # Return if any point is in front and the points themselves\n","\n","def camera_callback(image,data_dict):\n","    data_dict['image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))[:, :, :3]\n","\n","\n","def sem_callback(image,data_dict):\n","    image.convert(carla.ColorConverter.CityScapesPalette)\n","    data_dict['sem_image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))[:, :, :3]\n","\n","\n","def maintain_speed(s):\n","    if s >= PREFERRED_SPEED:\n","        return 0\n","    elif s < PREFERRED_SPEED - SPEED_THRESHOLD:\n","        return 0.7 # think of it as % of \"full gas\"\n","    else:\n","        return 0.4 # tweak this if the car is way over or under preferred speed\n","\n","\n","# function to get angle between the car and target waypoint\n","def get_angle(car,wp):\n","    vehicle_pos = car.get_transform()\n","    car_x = vehicle_pos.location.x\n","    car_y = vehicle_pos.location.y\n","    wp_x = wp.transform.location.x\n","    wp_y = wp.transform.location.y\n","\n","    # vector to waypoint\n","    x = (wp_x - car_x)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n","    y = (wp_y - car_y)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n","\n","    #car vector\n","    car_vector = vehicle_pos.get_forward_vector()\n","    degrees = math.degrees(np.arctan2(y, x) - np.arctan2(car_vector.y, car_vector.x))\n","    # extra checks on predicted angle when values close to 360 degrees are returned\n","    if degrees<-180:\n","        degrees = degrees + 360\n","    elif degrees > 180:\n","        degrees = degrees - 360\n","    return degrees\n","\n","def get_proper_angle(car,wp_idx,rte):\n","    # create a list of angles to next 5 waypoints starting with current\n","    next_angle_list = []\n","    for i in range(5):\n","        if wp_idx + i*3 <len(rte)-1:\n","            next_angle_list.append(get_angle(car,rte[wp_idx + i*3][0]))\n","    idx = 0\n","    while idx<len(next_angle_list)-2 and abs(next_angle_list[idx])>40:\n","        idx +=1\n","    return wp_idx+idx*3,next_angle_list[idx]\n","\n","def get_distant_angle(car,wp_idx,rte, delta=10):\n","    if wp_idx + delta < len(rte)-1:\n","        i = wp_idx + delta\n","    else:\n","        i = len(rte)-1\n","    intersection_detected = False\n","    for x in range(i-wp_idx):\n","        if rte[wp_idx+x][0].is_junction:\n","             intersection_detected = True\n","    angle = get_angle(car,rte[i][0])\n","    if not intersection_detected:\n","        result = 1\n","    elif angle <-10:\n","        result = 0\n","    elif angle>10:\n","        result = 2\n","    else:\n","        result = 1\n","    return result\n","\n","def draw_route(world, wp, route,seconds=3.0):\n","    if len(route)-wp <25:\n","        draw_colour = carla.Color(r=255, g=0, b=0)\n","    else:\n","        draw_colour = carla.Color(r=0, g=0, b=255)\n","    for i in range(10):\n","        if wp+i<len(route)-2:\n","            world.debug.draw_string(route[wp+i][0].transform.location, '^', draw_shadow=False,\n","                color=draw_colour, life_time=seconds,\n","                persistent_lines=True)\n","    return None\n","\n","def select_random_route(world, position,locs):\n","    point_a = position.location #we start at where the car is or last waypoint\n","    sampling_resolution = 1\n","    grp = GlobalRoutePlanner(world.get_map(), sampling_resolution)\n","    # now let' pick the longest possible route\n","    min_distance = 100\n","    result_route = None\n","    route_list = []\n","    for loc in locs: # we start trying all spawn points\n","                                #but we just exclude first at zero index\n","        cur_route = grp.trace_route(point_a, loc.location)\n","        if len(cur_route) > min_distance:\n","            route_list.append(cur_route)\n","    result_route = random.choice(route_list)\n","    return result_route\n","\n","\n","def exit_clean(world, vehicle):\n","    for sensor in world.get_actors().filter('*sensor*'):\n","        sensor.destroy()\n","    # vehicle.destroy\n","    for actor in world.get_actors().filter('*vehicle*'):\n","        actor.destroy()\n","    return None\n","\n","def collision_callback(event,data_dict):\n","    data_dict['collision']=True\n","\n","\n","def preprocessing_image(image):\n","    image = image.convert('L')\n","    image = image.point(lambda x: 255 if x >= 70 else 0, '1')\n","    width, height = image.size\n","    left = (width - 300) // 2\n","    top = (height - 250) // 2\n","    right = left + 300\n","    bottom = top + 250\n","    return image.crop((left, top, right, bottom))\n","\n","\n","class AutoNaviModel(nn.Module):\n","    def __init__(self):\n","        super(AutoNaviModel, self).__init__()\n","        self.conv_layers = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Flatten(),\n","            nn.Linear(64 * (HEIGHT // 8) * (WIDTH // 8), 128),\n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.Linear(128, 4),\n","            nn.ReLU(),\n","            nn.Flatten()\n","        )\n","        self.output_layer = nn.Linear(5, 1)  # 4 from image + 1 from input_2\n","\n","    def forward(self, image, navigational_direction):\n","        image_features = self.conv_layers(image)\n","\n","        combined = torch.cat((image_features, navigational_direction.unsqueeze(1)), dim=1)\n","\n","        output = self.output_layer(combined)\n","        return output\n","\n","\n","def control_car(sem_image, navigational_direction):\n","    sem_image_pil = Image.fromarray(sem_image.astype('uint8'), 'RGB')\n","\n","    transform1 = transforms.Compose([\n","        transforms.Resize((HEIGHT, WIDTH)),\n","        transforms.ToTensor(),\n","    ])\n","\n","    sem_image = transform1(sem_image_pil).unsqueeze(0).to(DEVICE)\n","    navigational_direction = torch.tensor([navigational_direction])\n","\n","    with torch.no_grad():\n","        auto_navi_output = auto_navi_model(sem_image, navigational_direction)\n","\n","    return float(auto_navi_output)\n","\n","\n","auto_navi_model_path = r'models\\auto_navi_model.pth'\n","auto_navi_model = torch.load(auto_navi_model_path, map_location=torch.device(DEVICE))\n","auto_navi_model.eval()\n","\n","#main loop\n","client = carla.Client('localhost', 2000)\n","world = client.get_world()\n","settings = world.get_settings()\n","settings.synchronous_mode = True  # Enable synchronous mode\n","settings.fixed_delta_seconds = 0.05  # Set the simulation time step (20 Hz)\n","world.apply_settings(settings)\n","\n","spawn_points = world.get_map().get_spawn_points()\n","\n","vehicle_bp = world.get_blueprint_library().filter('*model3*')\n","quit = False\n","WIDTH = 640\n","HEIGHT = 480\n","\n","\n","try:\n","    while True:\n","        print(\"-----------Start Iteration------------\")\n","\n","        vehi = 0\n","        # Create a traffic manager and set its parameters\n","        traffic_manager = client.get_trafficmanager(8000)  # You can specify a different port if needed\n","        traffic_manager.set_global_distance_to_leading_vehicle(2.0)  # Example setting: minimum distance to the leading vehicle\n","        traffic_manager.set_synchronous_mode(True)\n","\n","        # Now integrate it with vehicle spawning\n","        for i in range(0, len(spawn_points), 6):\n","            start_point = spawn_points[i]\n","            vehicle_blueprints = world.get_blueprint_library().filter('vehicle.*')\n","            vehicle_bp = random.choice(vehicle_blueprints)\n","            vehicle_1 = world.try_spawn_actor(vehicle_bp, start_point)\n","            time.sleep(0.5)\n","\n","            if vehicle_1:  # If the vehicle was successfully spawned\n","                traffic_manager.ignore_lights_percentage(vehicle_1, 0)  # Example setting: vehicles stop at traffic lights\n","                traffic_manager.vehicle_percentage_speed_difference(vehicle_1, -10)  # Reduce vehicle speed by 10%\n","                vehicle_1.set_autopilot(True, traffic_manager.get_port())  # Connect the vehicle with the traffic manager\n","                vehi += 1\n","                # print(vehi)\n","            # else:\n","            #     print(f\"Failed to spawn vehicle at index {i}.\")\n","\n","        # start_point = random.choice(spawn_points)\n","        vehicle_bp = world.get_blueprint_library().filter('*model3*')\n","        start_point = spawn_points[2]\n","        # start_point =  random.choice(spawn_points)\n","        vehicle = world.try_spawn_actor(vehicle_bp[0], start_point)\n","        while vehicle is None:\n","            # start_point =  random.choice(spawn_points)\n","            start_point = spawn_points[2]\n","            vehicle = world.try_spawn_actor(vehicle_bp[0], start_point)\n","            time.sleep(1)\n","\n","        blueprint_library = world.get_blueprint_library()\n","\n","        camera_bp = blueprint_library.find('sensor.camera.semantic_segmentation')\n","        camera_bp.set_attribute('fov', '90')\n","        camera_bp.set_attribute('image_size_x', f'{WIDTH}')\n","        camera_bp.set_attribute('image_size_y', f'{HEIGHT}')\n","        camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))\n","        camera_sem = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)\n","        camera_data = {'sem_image': np.zeros((HEIGHT,WIDTH,4))}\n","        camera_sem.listen(lambda image: sem_callback(image,camera_data))\n","\n","        collision_data ={'collision': False}\n","        collision_bp = world.get_blueprint_library().find('sensor.other.collision')\n","        collision_sensor = world.spawn_actor(collision_bp,carla.Transform(), attach_to = vehicle)\n","        collision_sensor.listen(lambda event: collision_callback(event,collision_data))\n","\n","        route = select_random_route(world, start_point,spawn_points)\n","        curr_wp = 5\n","        predicted_angle = 0\n","\n","        lidar_bp = generate_lidar_bp(blueprint_library)\n","        lidar_transform = carla.Transform(carla.Location(x=0, z=2))\n","        lidar = world.spawn_actor(lidar_bp, lidar_transform, attach_to=vehicle)\n","        point_list = o3d.geometry.PointCloud()\n","        lidar.listen(lambda data: lidar_callback(data, point_list))\n","        spectator = world.get_spectator()\n","        # generate_traffic(world, client, num_vehicles=80, num_pedestrians=10)\n","        while curr_wp<len(route)-1 :\n","            world.tick()\n","            update_spectator(vehicle)\n","\n","            draw_route(world, curr_wp, route,1)\n","            if cv2.waitKey(1) == ord('q'):\n","                quit = True\n","                exit_clean(world, vehicle)\n","                break\n","\n","            sem_image = camera_data['sem_image']\n","            sem_image = cv2.resize(sem_image, (WIDTH,HEIGHT))\n","\n","            if curr_wp >=len(route)-10 or collision_data['collision']:\n","                exit_clean(world, vehicle)\n","                break\n","\n","            while curr_wp<len(route)-2 and vehicle.get_transform().location.distance(route[curr_wp][0].transform.location)<5:\n","                curr_wp +=1 #move to next wp if we are too close\n","            curr_wp, predicted_angle = get_proper_angle(vehicle,curr_wp,route)\n","            distant_angle = get_distant_angle(vehicle,curr_wp,route)\n","\n","            v = vehicle.get_velocity()\n","            speed = round(3.6 * math.sqrt(v.x**2 + v.y**2 + v.z**2),0)\n","\n","            estimated_throttle = maintain_speed(speed)\n","\n","            steer_input = control_car(sem_image, distant_angle)\n","            if steer_input > 0.3:\n","                steer_input = 0.3\n","            if steer_input < -0.3:\n","                steer_input = -0.3\n","            if (steer_input > -0.001) and (steer_input < 0.001):\n","                steer_input = 0\n","\n","            vehicle.apply_control(carla.VehicleControl(throttle=float(estimated_throttle), steer=steer_input))\n","\n","\n","            if len(pcd1) > 0:\n","                latest_points = pcd1[-1]  # Get the latest point cloud frame\n","                has_points_in_front, mask, front_points = filter_points(latest_points)\n","                if has_points_in_front:\n","                    print(f\"Obstacle Detected, Steering Angle: {steer_input}, Speed: {speed}\")\n","                    vehicle.apply_control(carla.VehicleControl(throttle=0.0, brake=1.0))\n","                else:\n","                    print(f\"No Obstacle Detected, Steering Angle: {steer_input}, Speed: {speed}\")\n","\n","        if quit:\n","            break\n","\n","finally:\n","\n","    for sensor in world.get_actors().filter('*sensor*'):\n","        sensor.destroy()\n","    for actor in world.get_actors().filter('*vehicle*'):\n","        actor.destroy()"]},{"cell_type":"markdown","metadata":{},"source":["# Version 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0TDekOfIjmWl"},"outputs":[],"source":["from PIL import Image\n","import open3d as o3d\n","from torchvision import transforms\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import torch\n","from matplotlib import pyplot as plt\n","from agents.navigation.global_route_planner import GlobalRoutePlanner\n","import carla  # the sim library itself\n","import time  # to set a delay after each photo\n","import cv2  # to work with images from cameras\n","import numpy as np  # in this example to change image representation - re-shaping\n","import math\n","import sys\n","import random\n","# tweak to where you put carla\n","sys.path.append(\n","    r'C:\\Users\\Administrator\\Downloads\\WindowsNoEditor\\PythonAPI\\carla')\n","\n","\n","PREFERRED_SPEED = 20\n","SPEED_THRESHOLD = 2\n","\n","MAX_STEER_DEGREES = 30\n","STEERING_CONVERSION = 75\n","\n","CAMERA_POS_Z = 1.3\n","CAMERA_POS_X = 1.4\n","\n","HEIGHT = 180\n","WIDTH = 320\n","X_MIN = -6\n","X_MAX = -1\n","Y_MIN = -1\n","Y_MAX = 1\n","Z_MIN = -1\n","Z_MAX = 2\n","\n","WIDTH = 640\n","HEIGHT = 480\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","def update_spectator(vehicle):\n","    vehicle_transform = vehicle.get_transform()\n","\n","    # Position the spectator slightly behind and above the vehicle\n","    # Adjust x and z values as needed for view angle\n","    spectator_location = vehicle_transform.location + carla.Location(x=0, z=40)\n","    spectator_rotation = carla.Rotation(\n","        pitch=-90, yaw=vehicle_transform.rotation.yaw)  # Adjust pitch for angle\n","\n","    spectator_transform = carla.Transform(\n","        spectator_location, spectator_rotation)\n","    spectator.set_transform(spectator_transform)\n","\n","\n","pcd1 = []\n","\n","\n","def lidar_callback(point_cloud, point_list):\n","    \"\"\"Prepares a point cloud with intensity\n","    colors ready to be consumed by Open3D\"\"\"\n","    data = np.copy(np.frombuffer(point_cloud.raw_data, dtype=np.dtype('f4')))\n","    data = np.reshape(data, (int(data.shape[0] / 4), 4))\n","    points = data[:, :-1]\n","    points[:, :1] = -points[:, :1]\n","\n","    pcd1.append(points)\n","\n","\n","def generate_lidar_bp(blueprint_library):\n","    \"\"\"Generates a CARLA blue\n","    based on the script parameters\"\"\"\n","    lidar_bp = blueprint_library.find('sensor.lidar.ray_cast')\n","\n","    lidar_bp.set_attribute('upper_fov', str(10.0))\n","    lidar_bp.set_attribute('lower_fov', str(-30.0))\n","    lidar_bp.set_attribute('channels', str(64.0))\n","    lidar_bp.set_attribute('range', str(100.0))\n","    lidar_bp.set_attribute('rotation_frequency', str(20))\n","    lidar_bp.set_attribute('points_per_second', str(1000000))\n","    return lidar_bp\n","\n","\n","def filter_points(points, x_min=X_MIN, x_max=X_MAX, y_min=Y_MIN, y_max=Y_MAX, z_min=Z_MIN, z_max=Z_MAX):\n","    mask = (\n","        (points[:, 0] >= x_min) & (points[:, 0] <= x_max) &  # x-axis (front)\n","        (points[:, 1] >= y_min) & (points[:, 1] <= y_max) &  # y-axis (lateral)\n","        (points[:, 2] >= z_min) & (points[:, 2] <= z_max)    # z-axis (height)\n","    )\n","    # Return if any point is in front and the points themselves\n","    return np.any(mask), mask, points[mask]\n","\n","\n","def camera_callback(image, data_dict):\n","    data_dict['image'] = np.reshape(\n","        np.copy(image.raw_data), (image.height, image.width, 4))[:, :, :3]\n","\n","\n","def sem_callback(image, data_dict):\n","    image.convert(carla.ColorConverter.CityScapesPalette)\n","    data_dict['sem_image'] = np.reshape(\n","        np.copy(image.raw_data), (image.height, image.width, 4))[:, :, :3]\n","\n","\n","def maintain_speed(s):\n","    if s >= PREFERRED_SPEED:\n","        return 0\n","    elif s < PREFERRED_SPEED - SPEED_THRESHOLD:\n","        return 0.7  # think of it as % of \"full gas\"\n","    else:\n","        return 0.4  # tweak this if the car is way over or under preferred speed\n","\n","\n","# function to get angle between the car and target waypoint\n","def get_angle(car, wp):\n","    vehicle_pos = car.get_transform()\n","    car_x = vehicle_pos.location.x\n","    car_y = vehicle_pos.location.y\n","    wp_x = wp.transform.location.x\n","    wp_y = wp.transform.location.y\n","\n","    # vector to waypoint\n","    x = (wp_x - car_x)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n","    y = (wp_y - car_y)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n","\n","    # car vector\n","    car_vector = vehicle_pos.get_forward_vector()\n","    degrees = math.degrees(np.arctan2(\n","        y, x) - np.arctan2(car_vector.y, car_vector.x))\n","    # extra checks on predicted angle when values close to 360 degrees are returned\n","    if degrees < -180:\n","        degrees = degrees + 360\n","    elif degrees > 180:\n","        degrees = degrees - 360\n","    return degrees\n","\n","\n","def get_proper_angle(car, wp_idx, rte):\n","    # create a list of angles to next 5 waypoints starting with current\n","    next_angle_list = []\n","    for i in range(5):\n","        if wp_idx + i*3 < len(rte)-1:\n","            next_angle_list.append(get_angle(car, rte[wp_idx + i*3][0]))\n","    idx = 0\n","    while idx < len(next_angle_list)-2 and abs(next_angle_list[idx]) > 40:\n","        idx += 1\n","    return wp_idx+idx*3, next_angle_list[idx]\n","\n","\n","def get_distant_angle(car, wp_idx, rte, delta=10):\n","    if wp_idx + delta < len(rte)-1:\n","        i = wp_idx + delta\n","    else:\n","        i = len(rte)-1\n","    intersection_detected = False\n","    for x in range(i-wp_idx):\n","        if rte[wp_idx+x][0].is_junction:\n","            intersection_detected = True\n","    angle = get_angle(car, rte[i][0])\n","    if not intersection_detected:\n","        result = 1\n","    elif angle < -10:\n","        result = 0\n","    elif angle > 10:\n","        result = 2\n","    else:\n","        result = 1\n","    return result\n","\n","\n","def draw_route(world, wp, route, seconds=3.0):\n","    if len(route)-wp < 25:\n","        draw_colour = carla.Color(r=255, g=0, b=0)\n","    else:\n","        draw_colour = carla.Color(r=0, g=0, b=255)\n","    for i in range(10):\n","        if wp+i < len(route)-2:\n","            world.debug.draw_string(route[wp+i][0].transform.location, '^', draw_shadow=False,\n","                                    color=draw_colour, life_time=seconds,\n","                                    persistent_lines=True)\n","    return None\n","\n","\n","def select_random_route(world, position, locs):\n","    point_a = position.location  # we start at where the car is or last waypoint\n","    sampling_resolution = 1\n","    grp = GlobalRoutePlanner(world.get_map(), sampling_resolution)\n","    # now let' pick the longest possible route\n","    min_distance = 100\n","    result_route = None\n","    route_list = []\n","    for loc in locs:  # we start trying all spawn points\n","        # but we just exclude first at zero index\n","        cur_route = grp.trace_route(point_a, loc.location)\n","        if len(cur_route) > min_distance:\n","            route_list.append(cur_route)\n","    result_route = random.choice(route_list)\n","    return result_route\n","\n","\n","def exit_clean(world, vehicle):\n","    for sensor in world.get_actors().filter('*sensor*'):\n","        sensor.destroy()\n","    # vehicle.destroy\n","    for actor in world.get_actors().filter('*vehicle*'):\n","        actor.destroy()\n","    return None\n","\n","\n","def collision_callback(event, data_dict):\n","    data_dict['collision'] = True\n","\n","\n","def preprocessing_image(image):\n","    image = image.convert('L')\n","    image = image.point(lambda x: 255 if x >= 70 else 0, '1')\n","    width, height = image.size\n","    left = (width - 300) // 2\n","    top = (height - 250) // 2\n","    right = left + 300\n","    bottom = top + 250\n","    return image.crop((left, top, right, bottom))\n","\n","\n","class AutoNaviModel(nn.Module):\n","    def __init__(self):\n","        super(AutoNaviModel, self).__init__()\n","        self.conv_layers = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Flatten(),\n","            nn.Linear(64 * (HEIGHT // 8) * (WIDTH // 8), 128),\n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.Linear(128, 4),\n","            nn.ReLU(),\n","            nn.Flatten()\n","        )\n","        self.output_layer = nn.Linear(5, 1)  # 4 from image + 1 from input_2\n","\n","    def forward(self, image, navigational_direction):\n","        image_features = self.conv_layers(image)\n","\n","        combined = torch.cat(\n","            (image_features, navigational_direction.unsqueeze(1)), dim=1)\n","\n","        output = self.output_layer(combined)\n","        return output\n","\n","\n","def control_car(sem_image, navigational_direction):\n","    sem_image_pil = Image.fromarray(sem_image.astype('uint8'), 'RGB')\n","\n","    transform1 = transforms.Compose([\n","        transforms.Resize((HEIGHT, WIDTH)),\n","        transforms.ToTensor(),\n","    ])\n","\n","    sem_image = transform1(sem_image_pil).unsqueeze(0).to(DEVICE)\n","    navigational_direction = torch.tensor([navigational_direction])\n","\n","    with torch.no_grad():\n","        auto_navi_output = auto_navi_model(sem_image, navigational_direction)\n","\n","    return float(auto_navi_output)\n","\n","\n","auto_navi_model_path = r'models\\auto_navi_model.pth'\n","auto_navi_model = torch.load(\n","    auto_navi_model_path, map_location=torch.device(DEVICE))\n","auto_navi_model.eval()\n","\n","# main loop\n","client = carla.Client('localhost', 2000)\n","world = client.get_world()\n","settings = world.get_settings()\n","settings.synchronous_mode = True  # Enable synchronous mode\n","settings.fixed_delta_seconds = 0.05  # Set the simulation time step (20 Hz)\n","world.apply_settings(settings)\n","\n","spawn_points = world.get_map().get_spawn_points()\n","\n","vehicle_bp = world.get_blueprint_library().filter('*model3*')\n","quit = False\n","\n","\n","try:\n","    while True:\n","        print(\"-----------Start Iteration------------\")\n","\n","        vehi = 0\n","        # Create a traffic manager and set its parameters\n","        # You can specify a different port if needed\n","        traffic_manager = client.get_trafficmanager(8000)\n","        # Example setting: minimum distance to the leading vehicle\n","        traffic_manager.set_global_distance_to_leading_vehicle(2.0)\n","        traffic_manager.set_synchronous_mode(True)\n","\n","        # Now integrate it with vehicle spawning\n","        for i in range(0, len(spawn_points), 6):\n","            start_point = spawn_points[i]\n","            vehicle_blueprints = world.get_blueprint_library().filter('vehicle.*')\n","            vehicle_bp = random.choice(vehicle_blueprints)\n","            vehicle_1 = world.try_spawn_actor(vehicle_bp, start_point)\n","            time.sleep(0.5)\n","\n","            if vehicle_1:  # If the vehicle was successfully spawned\n","                # Example setting: vehicles stop at traffic lights\n","                traffic_manager.ignore_lights_percentage(vehicle_1, 0)\n","                traffic_manager.vehicle_percentage_speed_difference(\n","                    vehicle_1, -10)  # Reduce vehicle speed by 10%\n","                # Connect the vehicle with the traffic manager\n","                vehicle_1.set_autopilot(True, traffic_manager.get_port())\n","                vehi += 1\n","                # print(vehi)\n","            # else:\n","            #     print(f\"Failed to spawn vehicle at index {i}.\")\n","\n","        # start_point = random.choice(spawn_points)\n","        vehicle_bp = world.get_blueprint_library().filter('*model3*')\n","        start_point = spawn_points[2]\n","        # start_point =  random.choice(spawn_points)\n","        vehicle = world.try_spawn_actor(vehicle_bp[0], start_point)\n","        while vehicle is None:\n","            # start_point =  random.choice(spawn_points)\n","            start_point = spawn_points[2]\n","            vehicle = world.try_spawn_actor(vehicle_bp[0], start_point)\n","            time.sleep(1)\n","\n","        blueprint_library = world.get_blueprint_library()\n","\n","        camera_bp = blueprint_library.find(\n","            'sensor.camera.semantic_segmentation')\n","        camera_bp.set_attribute('fov', '90')\n","        camera_bp.set_attribute('image_size_x', f'{WIDTH}')\n","        camera_bp.set_attribute('image_size_y', f'{HEIGHT}')\n","        camera_init_trans = carla.Transform(\n","            carla.Location(z=CAMERA_POS_Z, x=CAMERA_POS_X))\n","        camera_sem = world.spawn_actor(\n","            camera_bp, camera_init_trans, attach_to=vehicle)\n","        camera_data = {'sem_image': np.zeros((HEIGHT, WIDTH, 4))}\n","        camera_sem.listen(lambda image: sem_callback(image, camera_data))\n","\n","        collision_data = {'collision': False}\n","        collision_bp = world.get_blueprint_library().find('sensor.other.collision')\n","        collision_sensor = world.spawn_actor(\n","            collision_bp, carla.Transform(), attach_to=vehicle)\n","        collision_sensor.listen(\n","            lambda event: collision_callback(event, collision_data))\n","\n","        route = select_random_route(world, start_point, spawn_points)\n","        curr_wp = 5\n","        predicted_angle = 0\n","\n","        lidar_bp = generate_lidar_bp(blueprint_library)\n","        lidar_transform = carla.Transform(carla.Location(x=0, z=2))\n","        lidar = world.spawn_actor(lidar_bp, lidar_transform, attach_to=vehicle)\n","        point_list = o3d.geometry.PointCloud()\n","        lidar.listen(lambda data: lidar_callback(data, point_list))\n","        spectator = world.get_spectator()\n","        # generate_traffic(world, client, num_vehicles=80, num_pedestrians=10)\n","        while curr_wp < len(route)-1:\n","            world.tick()\n","            update_spectator(vehicle)\n","\n","            draw_route(world, curr_wp, route, 1)\n","            if cv2.waitKey(1) == ord('q'):\n","                quit = True\n","                exit_clean(world, vehicle)\n","                break\n","\n","            sem_image = camera_data['sem_image']\n","            sem_image = cv2.resize(sem_image, (WIDTH, HEIGHT))\n","\n","            if curr_wp >= len(route)-10 or collision_data['collision']:\n","                exit_clean(world, vehicle)\n","                break\n","\n","            while curr_wp < len(route)-2 and vehicle.get_transform().location.distance(route[curr_wp][0].transform.location) < 5:\n","                curr_wp += 1  # move to next wp if we are too close\n","            curr_wp, predicted_angle = get_proper_angle(\n","                vehicle, curr_wp, route)\n","            distant_angle = get_distant_angle(vehicle, curr_wp, route)\n","\n","            v = vehicle.get_velocity()\n","            speed = round(3.6 * math.sqrt(v.x**2 + v.y**2 + v.z**2), 0)\n","\n","            estimated_throttle = maintain_speed(speed)\n","\n","            steer_input = control_car(sem_image, distant_angle)\n","            if steer_input > 0.3:\n","                steer_input = 0.3\n","            if steer_input < -0.3:\n","                steer_input = -0.3\n","            if (steer_input > -0.001) and (steer_input < 0.001):\n","                steer_input = 0\n","\n","            vehicle.apply_control(carla.VehicleControl(\n","                throttle=float(estimated_throttle), steer=steer_input))\n","\n","            if len(pcd1) > 0:\n","                latest_points = pcd1[-1]  # Get the latest point cloud frame\n","                has_points_in_front, mask, front_points = filter_points(\n","                    latest_points)\n","                if has_points_in_front:\n","                    print(f\"Obstacle Detected, Steering Angle: {\n","                          steer_input}, Speed: {speed}\")\n","                    vehicle.apply_control(\n","                        carla.VehicleControl(throttle=0.0, brake=1.0))\n","                else:\n","                    print(f\"No Obstacle Detected, Steering Angle: {\n","                          steer_input}, Speed: {speed}\")\n","\n","        if quit:\n","            break\n","\n","finally:\n","\n","    for sensor in world.get_actors().filter('*sensor*'):\n","        sensor.destroy()\n","    for actor in world.get_actors().filter('*vehicle*'):\n","        actor.destroy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNUByJlQ608Xxr9/yJL81Gj","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
