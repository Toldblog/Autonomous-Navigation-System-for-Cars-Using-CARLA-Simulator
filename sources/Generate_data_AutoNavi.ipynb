{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla #the sim library itself\n",
    "import time # to set a delay after each photo\n",
    "import cv2 #to work with images from cameras\n",
    "import numpy as np #in this example to change image representation - re-shaping\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "\n",
    "\n",
    "from .utils import *\n",
    "from .constants import *\n",
    "\n",
    "# connect to the sim \n",
    "client = carla.Client('localhost', 2000)\n",
    "\n",
    "time.sleep(5)\n",
    "client.set_timeout(25)\n",
    "\n",
    "world = client.get_world()\n",
    "\n",
    "# ensure sync mode on \n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = True\n",
    "settings.fixed_delta_seconds = 0.1\n",
    "settings.no_rendering_mode = False\n",
    "world.apply_settings(settings)\n",
    "\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "\n",
    "#clean up any existing cars\n",
    "for actor in world.get_actors().filter('*vehicle*'):\n",
    "    actor.destroy()\n",
    "\n",
    "#look for a blueprint of Tesla m3 car\n",
    "vehicle_bp = world.get_blueprint_library().filter('*model3*')\n",
    "\n",
    "def exit_clean():\n",
    "    #clean up\n",
    "    cv2.destroyAllWindows()\n",
    "    camera_sem.stop()\n",
    "    for sensor in world.get_actors().filter('*sensor*'):\n",
    "        sensor.destroy()\n",
    "    for actor in world.get_actors().filter('*vehicle*'):\n",
    "        actor.destroy()\n",
    "    return None\n",
    "\n",
    "data_path = '../data/automatic-navigation/segmentation'\n",
    "\n",
    "#main loop\n",
    "img_counter = 0\n",
    "quit = False\n",
    "while img_counter < 10000:\n",
    "    start_point = random.choice(spawn_points)\n",
    "    vehicle = world.try_spawn_actor(vehicle_bp[0], start_point)\n",
    "    time.sleep(2)\n",
    "    # setting semantic camera\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.semantic_segmentation')\n",
    "    camera_bp.set_attribute('image_size_x', '640') # this ratio works in CARLA 9.13 on Windows\n",
    "    camera_bp.set_attribute('image_size_y', '480')\n",
    "    camera_bp.set_attribute('fov', '90')\n",
    "    camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))\n",
    "    camera_sem = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "    image_w = 640\n",
    "    image_h = 480\n",
    "\n",
    "    camera_data = {'sem_image': np.zeros((image_h,image_w,4)),\n",
    "                   'rgb_image': np.zeros((image_h,image_w,4))}\n",
    "\n",
    "        # this actually opens a live stream from the cameras\n",
    "    camera_sem.listen(lambda image: sem_callback(image,camera_data))\n",
    "    # adding collision sensor\n",
    "    \n",
    "    collision_data ={'collision': False}\n",
    "    \n",
    "    collision_bp = world.get_blueprint_library().find('sensor.other.collision')\n",
    "    collision_sensor = world.spawn_actor(collision_bp,carla.Transform(), attach_to = vehicle)\n",
    "    collision_sensor.listen(lambda event: collision_callback(event,collision_data))    \n",
    "    \n",
    "    prev_position = vehicle.get_transform()\n",
    "    # getting a random route for the car\n",
    "    route = select_random_route(start_point,spawn_points)\n",
    "    curr_wp = 5 #we will be tracking waypoints in the route and switch to next one when we get close to current one\n",
    "    predicted_angle = 0\n",
    "    PREFERRED_SPEED = 40 # setting speed at start of new route\n",
    "    \n",
    "    while curr_wp<len(route)-1 and not collision_data['collision']:\n",
    "        # Carla Tick\n",
    "        world.tick()\n",
    "        \n",
    "        if curr_wp >=len(route)-5: # within 10 points of end, the route is done\n",
    "            exit_clean()\n",
    "            break\n",
    "        while curr_wp<len(route)-2 and vehicle.get_transform().location.distance(route[curr_wp][0].transform.location)<5:\n",
    "            curr_wp +=1 #move to next wp if we are too close\n",
    "        curr_wp, predicted_angle = get_proper_angle(vehicle,curr_wp,route)\n",
    "        gen_dir_angle = get_distant_angle(vehicle,curr_wp,route,30)\n",
    "        \n",
    "        v = vehicle.get_velocity()\n",
    "        speed = round(3.6 * math.sqrt(v.x**2 + v.y**2 + v.z**2),0)\n",
    "        estimated_throttle = maintain_speed(speed)\n",
    "\n",
    "        steer_input = predicted_angle\n",
    "        # limit steering to max angel, say 40 degrees\n",
    "        if predicted_angle<-MAX_STEER_DEGREES:\n",
    "            steer_input = -MAX_STEER_DEGREES\n",
    "        elif predicted_angle>MAX_STEER_DEGREES:\n",
    "            steer_input = MAX_STEER_DEGREES\n",
    "        # conversion from degrees to -1 to +1 input for apply control function is applied below in steering input\n",
    "        current_position = vehicle.get_transform()\n",
    "        sem_im = camera_data['sem_image']\n",
    "        vehicle.apply_control(carla.VehicleControl(throttle=estimated_throttle, steer=steer_input/STEERING_CONVERSION))\n",
    "        #write images\n",
    "        if current_position.location.distance(prev_position.location)>5:\n",
    "            prev_position = current_position\n",
    "            img_counter += 1\n",
    "            time_grab = time.time_ns()\n",
    "            cv2.imwrite(f'{data_path}/%06d_%s_%s.png' % (time_grab, gen_dir_angle,round(predicted_angle,0)), sem_im)\n",
    "    \n",
    "    if quit:\n",
    "        break\n",
    "exit_clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add some noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla #the sim library itself\n",
    "import time # to set a delay after each photo\n",
    "import cv2 #to work with images from cameras\n",
    "import numpy as np #in this example to change image representation - re-shaping\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "\n",
    "from .utils import *\n",
    "from .constants import *\n",
    "\n",
    "client = carla.Client('localhost', 2000)\n",
    "time.sleep(5)\n",
    "client.set_timeout(25)\n",
    "\n",
    "# get world and spawn points\n",
    "world = client.get_world()\n",
    "\n",
    " \n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = False\n",
    "if settings.synchronous_mode:\n",
    "    settings.fixed_delta_seconds = 0.05\n",
    "world.apply_settings(settings)\n",
    "\n",
    "cleanup(world=world)\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "\n",
    "quit = False\n",
    "while not quit:\n",
    "    start_point = random.choice(spawn_points)\n",
    "    vehicle_bp = world.get_blueprint_library().filter('*model3*')\n",
    "    vehicle = world.try_spawn_actor(vehicle_bp[0], start_point)\n",
    "    time.sleep(2)\n",
    " \n",
    "    #RGB CAM\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', str(CAM_WIDTH)) # this ratio works in CARLA 9.14 on Windows\n",
    "    camera_bp.set_attribute('image_size_y', str(CAM_HEIGHT))\n",
    "    camera_bp.set_attribute('fov', str(FOV))\n",
    "    camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))\n",
    "    #this creates the camera in the sim\n",
    "    camera = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "    image_w = camera_bp.get_attribute('image_size_x').as_int()\n",
    "    image_h = camera_bp.get_attribute('image_size_y').as_int()\n",
    "    camera_data = {'image': np.zeros((image_h,image_w,3)),\n",
    "                'sem_image': np.zeros((image_h,image_w,3))}\n",
    "    # this actually opens a live stream from the camera\n",
    "    camera.listen(lambda image: camera_callback(image,camera_data))\n",
    "\n",
    "    #Semantgic cam\n",
    "    sem_camera_bp = world.get_blueprint_library().find('sensor.camera.semantic_segmentation')\n",
    "    sem_camera_bp.set_attribute('image_size_x', str(CAM_WIDTH)) # this ratio works in CARLA 9.14 on Windows\n",
    "    sem_camera_bp.set_attribute('image_size_y', str(CAM_HEIGHT))\n",
    "    sem_camera_bp.set_attribute('fov', str(FOV))\n",
    "    #this creates the camera in the sim\n",
    "    sem_camera = world.spawn_actor(sem_camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "    image_w = sem_camera_bp.get_attribute('image_size_x').as_int()\n",
    "    image_h = sem_camera_bp.get_attribute('image_size_y').as_int()\n",
    "    sem_camera_data = {'image': np.zeros((image_h,image_w,3))}\n",
    "    # this actually opens a live stream from the camera\n",
    "    #sem_camera.listen(lambda image: camera_callback(image,sem_camera_data))\n",
    "    sem_camera.listen(lambda image: sem_callback(image,camera_data))\n",
    "\n",
    "    cv2.namedWindow('RGB Camera',cv2.WINDOW_AUTOSIZE)\n",
    "    cv2.imshow('RGB Camera',camera_data['image'])\n",
    "    #make a route\n",
    "    route = select_random_route(start_point,spawn_points)\n",
    "    for idx, waypoint in enumerate(route): # move the car through the route\n",
    "        #world.tick()\n",
    "        transform = waypoint[0].transform\n",
    "        vehicle.set_transform(transform)\n",
    "        vehicle.apply_control(carla.VehicleControl(throttle=0, steer=0, brake=1))\n",
    "        time.sleep(2) #these delays seem to be necessary for teh car to take the position before a shot is taken\n",
    "        initial_yaw = waypoint[0].transform.rotation.yaw\n",
    "        \n",
    "        for i in range(5):\n",
    "            #world.tick()         \n",
    "            trans = waypoint[0].transform\n",
    "            angle_adj = random.randrange(-YAW_ADJ_DEGREES, YAW_ADJ_DEGREES, 1)\n",
    "            trans.rotation.yaw = initial_yaw +angle_adj \n",
    "            vehicle.set_transform(trans)\n",
    "            vehicle.apply_control(carla.VehicleControl(throttle=0, steer=0, brake=1))\n",
    "            time.sleep(1)  #these delays seem to be necessary for the car to take the position before a shot is taken\n",
    "            gen_dir_angle = get_distant_angle(vehicle,idx,route,30) # general angle taken before spinning the car\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                quit = True\n",
    "                break\n",
    "            # Display with imshow\n",
    "            cv2.imshow('RGB Camera',camera_data['image'])\n",
    "            # save semantic image watching out for end of route    \n",
    "            if idx +5 < len(route)-1:\n",
    "                predicted_angle = get_angle(vehicle,route[idx+5][0]) # we always get the angle to +5 waypoint ahead of us\n",
    "                \n",
    "                time_grab = time.time_ns()\n",
    "                sem_image = camera_data['sem_image']\n",
    "                if np.sum(sem_image) > 0:   #check for black images\n",
    "                    cv2.imwrite('_img/%06d_%s_%s.png' % (time_grab, gen_dir_angle,round(predicted_angle,0)), sem_image)\n",
    "    cleanup(world=world)\n",
    "    if quit:\n",
    "        break\n",
    "    # Break loop if user presses q\n",
    "cv2.destroyAllWindows()\n",
    "cleanup(world=world)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla #the sim library itself\n",
    "import time # to set a delay after each photo\n",
    "import cv2 #to work with images from cameras\n",
    "import numpy as np #in this example to change image representation - re-shaping\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "\n",
    "from .utils import *\n",
    "from .constants import *\n",
    "\n",
    "client = carla.Client('localhost', 2000)\n",
    "time.sleep(5)\n",
    "client.set_timeout(25)\n",
    "\n",
    "# get world and spawn points\n",
    "world = client.get_world()\n",
    "\n",
    " \n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = False\n",
    "if settings.synchronous_mode:\n",
    "    settings.fixed_delta_seconds = 0.05\n",
    "world.apply_settings(settings)\n",
    "\n",
    "cleanup(world=world)\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "\n",
    "quit = False\n",
    "while not quit:\n",
    "    start_point = random.choice(spawn_points)\n",
    "    vehicle_bp = world.get_blueprint_library().filter('*model3*')\n",
    "    vehicle = world.try_spawn_actor(vehicle_bp[0], start_point)\n",
    "    time.sleep(2)\n",
    " \n",
    "    #RGB CAM\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', str(CAM_WIDTH)) # this ratio works in CARLA 9.14 on Windows\n",
    "    camera_bp.set_attribute('image_size_y', str(CAM_HEIGHT))\n",
    "    camera_bp.set_attribute('fov', str(FOV))\n",
    "    camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))\n",
    "    #this creates the camera in the sim\n",
    "    camera = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "    image_w = camera_bp.get_attribute('image_size_x').as_int()\n",
    "    image_h = camera_bp.get_attribute('image_size_y').as_int()\n",
    "    camera_data = {'image': np.zeros((image_h,image_w,3)),\n",
    "                'sem_image': np.zeros((image_h,image_w,3))}\n",
    "    # this actually opens a live stream from the camera\n",
    "    camera.listen(lambda image: camera_callback(image,camera_data))\n",
    "\n",
    "    #Semantgic cam\n",
    "    sem_camera_bp = world.get_blueprint_library().find('sensor.camera.semantic_segmentation')\n",
    "    sem_camera_bp.set_attribute('image_size_x', str(CAM_WIDTH)) # this ratio works in CARLA 9.14 on Windows\n",
    "    sem_camera_bp.set_attribute('image_size_y', str(CAM_HEIGHT))\n",
    "    sem_camera_bp.set_attribute('fov', str(FOV))\n",
    "    #this creates the camera in the sim\n",
    "    sem_camera = world.spawn_actor(sem_camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "    image_w = sem_camera_bp.get_attribute('image_size_x').as_int()\n",
    "    image_h = sem_camera_bp.get_attribute('image_size_y').as_int()\n",
    "    sem_camera_data = {'image': np.zeros((image_h,image_w,3))}\n",
    "    # this actually opens a live stream from the camera\n",
    "    #sem_camera.listen(lambda image: camera_callback(image,sem_camera_data))\n",
    "    sem_camera.listen(lambda image: sem_callback(image,camera_data))\n",
    "\n",
    "    cv2.namedWindow('RGB Camera',cv2.WINDOW_AUTOSIZE)\n",
    "    cv2.imshow('RGB Camera',camera_data['image'])\n",
    "    #make a route\n",
    "    route = select_random_route(start_point,spawn_points)\n",
    "    gen_dir_angle = 0 # in case we did not get a general GPS direction\n",
    "    for idx, waypoint in enumerate(route): # move the car through the route\n",
    "        \n",
    "        transform = waypoint[0].transform\n",
    "        vehicle.set_transform(transform)\n",
    "        vehicle.apply_control(carla.VehicleControl(throttle=0, steer=0, brake=1))\n",
    "        time.sleep(2) #these delays seem to be necessary for teh car to take the position before a shot is taken\n",
    "        initial_yaw = waypoint[0].transform.rotation.yaw\n",
    "        # GPS general direction is only taken outside intersections\n",
    "        # so that direction is retained throughout the same intersection until it is finished\n",
    "        if not waypoint[0].is_intersection and not waypoint[0].is_junction:\n",
    "            gen_dir_angle = get_distant_angle(vehicle,idx,route,30) # general angle taken before spinning the car\n",
    "        # logic to detect a lane change and ignore/not take those images\n",
    "        draw_route(world, idx, route,seconds=5.0)\n",
    "        lane_change = False\n",
    "        if not waypoint[0].is_intersection and not waypoint[0].is_junction:\n",
    "            if idx < len(route)-2:\n",
    "                if route[idx][0].lane_id != route[idx+1][0].lane_id:\n",
    "                    lane_change = True\n",
    "        if not lane_change:\n",
    "            for i in range(5):\n",
    "                trans = waypoint[0].transform\n",
    "                angle_adj = random.randrange(-YAW_ADJ_DEGREES, YAW_ADJ_DEGREES, 1)\n",
    "                trans.rotation.yaw = initial_yaw +angle_adj \n",
    "                vehicle.set_transform(trans)\n",
    "                vehicle.apply_control(carla.VehicleControl(throttle=0, steer=0, brake=1))\n",
    "                time.sleep(1)  #these delays seem to be necessary for the car to take the position before a shot is taken\n",
    "                \n",
    "                if cv2.waitKey(1) == ord('q'):\n",
    "                    quit = True\n",
    "                    break\n",
    "                # Display with imshow\n",
    "                cv2.imshow('RGB Camera',camera_data['image'])\n",
    "                # save semantic image watching out for end of route    \n",
    "                if idx +5 < len(route)-1:\n",
    "                    predicted_angle = get_angle(vehicle,route[idx+5][0]) # we always get the angle to +5 waypoint ahead of us\n",
    "                    \n",
    "                    time_grab = time.time_ns()\n",
    "                    sem_image = camera_data['sem_image']\n",
    "                    if np.sum(sem_image) > 0:   #check for black images\n",
    "                        cv2.imwrite('_img/%06d_%s_%s.png' % (time_grab, gen_dir_angle,round(predicted_angle,0)), sem_image)\n",
    "    cleanup(world=world)\n",
    "    if quit:\n",
    "        break\n",
    "    # Break loop if user presses q\n",
    "cv2.destroyAllWindows()\n",
    "cleanup(world=world)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
